{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import torch \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Create a straight line dataset using the linear regression formula (weight * X + bias).\n",
    "\n",
    "1. Set weight=0.3 and bias=0.9 there should be at least 100 datapoints total.\n",
    "2. Split the data into 80% training, 20% testing.\n",
    "3. Plot the training and testing data so it becomes visual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 0.3\n",
    "bias = 0.9\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.01\n",
    "X = torch.arange(start,end,step,dtype=torch.float).unsqueeze(dim=1)\n",
    "y = weights * X + bias\n",
    "print(f\"Number of X samples: {len(X)}\")\n",
    "print(f\"Number of y samples: {len(y)}\")\n",
    "print(f\"First 10 X & y samples:\\nX: {X[:10]}\\ny: {y[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = int(0.8*len(X))\n",
    "X_train,y_train = X[:train_test_split],y[:train_test_split]\n",
    "X_test,y_test = X[train_test_split:],y[train_test_split:]\n",
    "len(X_train),len(X_test),len(y_train),len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,test_data=X_test,train_label=y_train,test_label=y_test,predictions=None):\n",
    "    \"\"\"\n",
    "    Plot the train,test data and prediction if available\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    plt.scatter(train_data,train_label,c=\"b\",label=\"Training data\")\n",
    "\n",
    "    plt.scatter(test_data,test_label,c=\"g\",label=\"Testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data,predictions,c=\"r\",label = \"Predictions\")\n",
    "\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Build a PyTorch model by subclassing nn.Module.\n",
    "\n",
    "1. Inside should be a randomly initialized nn.Parameter() with requires_grad=True, one for weights and one for bias.\n",
    "2. Implement the forward() method to compute the linear regression function you used to create the dataset in 1.\n",
    "3. Once you've constructed the model, make an instance of it and check its state_dict().\n",
    "`Note: If you'd like to use nn.Linear() instead of nn.Parameter() you can.`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1,out_features=1,dtype=torch.float,device=device)\n",
    "\n",
    "    def forward(self,x:torch.Tensor)->torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = LinearRegressionModel()\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create a loss function and optimizer using nn.L1Loss() and torch.optim.SGD(params, lr) respectively.\n",
    "\n",
    "1. Set the learning rate of the optimizer to be 0.01 and the parameters to optimize should be the model parameters\n",
    "from the model you created in 2.\n",
    "2. Write a training loop to perform the appropriate training steps for 300 epochs.\n",
    "3. The training loop should test the model on the test dataset every 20 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.to(device)\n",
    "next(model_0.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Model dot train\n",
    "    model_0.train()\n",
    "    # Do the forward Pass\n",
    "    y_preds = model_0(X_train)\n",
    "    # Calculate the loss\n",
    "    loss = loss_fn(y_preds,y_train)\n",
    "    # Optimizer Zero grad\n",
    "    optimizer.zero_grad()\n",
    "    # Loss backward\n",
    "    loss.backward()\n",
    "    # Optimizer Step\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        # Testing\n",
    "        # Model dot eval\n",
    "        model_0.eval()\n",
    "        # With torch inference mode\n",
    "        with torch.inference_mode():\n",
    "            y_test_preds = model_0(X_test)\n",
    "            test_loss = loss_fn(y_test_preds,y_test)\n",
    "    # Print out what's happening\n",
    "    print(f\"Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Make predictions with the trained model on the test data.\n",
    "\n",
    "1. Visualize these predictions against the original training and testing data (note: you may need to make sure the predictions are not on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "plot_predictions(predictions=y_preds.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Save your trained model's state_dict() to file.\n",
    "\n",
    "1. Create a new instance of your model class you made in 2. and load in the state_dict() you just saved to it.\n",
    "2. Perform predictions on your test data with the loaded model and confirm they match the original model predictions from 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"01_Pytorch_Workflow_Excerise_Model.pt\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(),f=MODEL_SAVE_PATH)\n",
    "print(f\"Saved model parameters: \\n{model_0.state_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LinearRegressionModel()\n",
    "model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = model_1(X_test)\n",
    "y_preds == loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
