{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are 3 areas in industry where computer vision is currently being used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Defects detection on assembly line <br>\n",
    "II. Self-driving vehicles <br>\n",
    "III. Face recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Overfitting occurs when a machine learning model is trained on the training data repeatedly. Over time the model will perform very well on the training data, but poorly on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. Note: there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Hold-out: Splitting the whole dataset to training and testing datasets. <br>\n",
    "II. Data Augmentation: Creates new data from the available data. <br>\n",
    "III. Regularization:  This makes the model learn broader patterns rather then memorizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Spend 20-minutes reading and clicking through the <a href=\"https://poloclub.github.io/cnn-explainer/\"> CNN Explainer website </a>.\n",
    "    * Upload your own example image using the \"upload\" button and see what happens in each layer of a CNN as your image passes through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the <a href=\"https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST\">torchvision.datasets.MNIST()</a> train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='data',train=True,download=True,transform=ToTensor())\n",
    "test_data = datasets.MNIST(root='data',train=False,download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name =  train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAACiCAYAAAC6cvAnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeEklEQVR4nO3deVzVVf7H8c8VlFBwiSQ3XDJwm8rGJkrFct8VJXGbTKdHbjMPo9RyGdNccHyAOjOVpdm4oDW4hE6apZZlmamjk2smVohjZokbipLK9/dHIz/P+V4493LvhYu+no9Hf7zP/Z7vPRdO8OHrOd+vw7IsSwAAAAAUqExJDwAAAADwdxTNAAAAgAFFMwAAAGBA0QwAAAAYUDQDAAAABhTNAAAAgAFFMwAAAGBA0QwAAAAYUDQDAAAABhTNQAlwOBwyZcqUkh4GSinmDzzFHALc5xdF8+DBg8XhcBT434kTJ0p6iCjFdu/eLZ06dZKKFStKaGiodOjQQb766quSHhZKCeYPPMUcgidyc3PlxRdflBo1akhwcLBER0fLpk2bSnpYtyWHZVlWSQ9i+/bt8u233yptlmXJ8OHDpW7dunLw4MESGhlKuz179kiLFi0kIiJChg0bJnl5eTJv3jw5c+aM7Ny5Uxo0aFAi47py5YoEBgZKYGBgibw/XMP8gaeYQ/BU//79ZdWqVZKQkCCRkZGyePFi2bVrl2zZskVatmxZ0sO7rfhF0ezM559/LjExMTJjxgyZMGFCSQ8HpVTXrl1l+/btkp6eLmFhYSIicvLkSYmKipIOHTrI6tWrS3iE8GfMH3iKOQRP7Ny5U6KjoyUpKUnGjBkjIr/+wfOb3/xGwsPD5YsvvijhEbru0qVLUqFChZIehkf8YnmGM2+//bY4HA4ZMGCAV8/7448/ypAhQ6RWrVoSFBQk1atXl549e0pGRoZy3IYNGyQmJkYqVKggoaGh0rVrV+WKd3JysjgcDjl27JjtPcaPHy/lypWTs2fP5rft2LFDOnXqJJUqVZLy5cvLY489Jtu2bVP6TZkyRRwOhxw9elQGDx4slStXlkqVKsmQIUMkJyfHq1+H28Vnn30m7dq1y/9lJSJSvXp1eeyxx2TdunVy8eJFr73X4MGDJSQkRE6cOCGxsbESEhIiVatWlTFjxsj169eVY/X1hO5+75ctWybNmjWT4OBgufPOO6Vfv35y/Phxr30W/Ir5A08xh+CJVatWSUBAgAwdOjS/7Y477pCnn35atm/f7rWv+SeffFLgEtm6desqx5rqI5H/n4vffvutdOnSRUJDQ2XgwIEi8mvxPHr0aImIiJCgoCBp0KCBJCcni59ew1X4ZdF89epVWbFihTRv3tz2zfJUXFycpKWlyZAhQ2TevHkyatQoyc7OlszMzPxjUlJSpGvXrhISEiKzZs2SSZMmyaFDh6Rly5b5xXV8fLw4HA5ZsWKF7T1WrFghHTp0kCpVqoiIyMcffyytWrWSCxcuyOTJkyUxMVHOnTsnbdq0kZ07d9r6x8fHS3Z2tsycOVPi4+Nl8eLF8vLLL3v163C7yM3NleDgYFt7+fLl5ZdffpEDBw549f2uX78uHTt2lLCwMElOTpbHHntMZs+eLQsWLHCpvyvf+xkzZsigQYMkMjJS5syZIwkJCfLRRx9Jq1at5Ny5c179PLc75g88xRyCJ/7zn/9IVFSUVKxYUWl/+OGHRUS8tja+UaNGkpKSovz3yiuvSNmyZSU8PDz/OFfqoxuuXbsmHTt2lPDwcElOTpa4uDixLEt69Oghc+fOlU6dOsmcOXOkQYMGMnbsWHn++ee98ll8yvJD7733niUi1rx587x63rNnz1oiYiUlJRV4THZ2tlW5cmXrmWeeUdp//PFHq1KlSkr7o48+ajVr1kw5bufOnZaIWEuXLrUsy7Ly8vKsyMhIq2PHjlZeXl7+cTk5OVa9evWs9u3b57dNnjzZEhHrD3/4g3LOXr16WWFhYe5/YFj33XefFRUVZV27di2/LTc316pdu7YlItaqVau89l5PPfWUJSLW1KlTlfYHH3zQNk9ExJo8eXJ+dvV7n5GRYQUEBFgzZsxQjtu/f78VGBhoa4dnmD/wFHMInmjSpInVpk0bW/vBgwctEbHeeOMNn7xvXl6e1a1bNyskJMQ6ePCgZVnu1Uc35uK4ceOUY9esWWOJiDV9+nSl/YknnrAcDod19OhRn3web/HLK81vv/22lC1bVuLj47163uDgYClXrpx88sknytKJm23atEnOnTsn/fv3l9OnT+f/FxAQINHR0bJly5b8Y/v27Su7d+9WNjGmpqZKUFCQ9OzZU0R+/SswPT1dBgwYIFlZWfnnu3TpkrRt21a2bt0qeXl5yhiGDx+u5JiYGMnKypILFy5460tx2xg5cqQcOXJEnn76aTl06JAcOHBABg0aJCdPnhQRkcuXL3v9PZ19/7777rsi9735e//uu+9KXl6exMfHK/OzWrVqEhkZqcxPeI75A08xh+CJy5cvS1BQkK39jjvuyH/dF6ZNmybr1q2TxYsXS+PGjUXEvfrohhEjRij5/fffl4CAABk1apTSPnr0aLEsSzZs2OCTz+Mtfrdt9uLFi7J27dr8f15y5fib14QFBARI1apVnR4bFBQks2bNktGjR8vdd98tjzzyiHTr1k0GDRok1apVExGR9PR0ERFp06aN03Pc/E8kffr0keeff15SU1NlwoQJYlmWrFy5Ujp37px/3I3zPfXUUwV+hvPnz+cv5RARqV27tvL6jdfOnj1r+ycaFG748OFy/PhxSUpKkiVLloiIyEMPPSQvvPCCzJgxQ0JCQgrs687cuuGOO+6wHVOlSpUC/0jTmb736enpYlmWREZGOu1ftmxZl94HrmH+wFPMIXgiODhYcnNzbe1XrlzJf70gRZk/IiIffPCBvPzyyzJ+/HiJi4vLb3enPhIRCQwMlFq1ailtx44dkxo1akhoaKjS3qhRo/zX/ZnfFc1r1qyRnJyc/AXjJsnJycp6qzp16tjW1dwsISFBunfvLmvWrJEPP/xQJk2aJDNnzpSPP/5YHnzwwfyrvikpKfmF9M1uvj1PjRo1JCYmRlasWCETJkyQL7/8UjIzM2XWrFn5x9w4X1JSkjRt2tTpmPQfmgEBAU6Ps0rBInl/NGPGDBkzZowcPHhQKlWqJPfdd1/+HVmioqIK7Ofu3BIp+HvnKtP3Pi8vTxwOh2zYsMHpsYX9AkbRMH/gKeYQiqp69epOn1Vx418qatSoUWDfosyf77//XgYOHCjt27eX6dOnK6+5Ux+J/HqhskwZv1zQUGR+VzQvX75cQkJCpEePHi4dP2jQIOU+hYX91XVD/fr1ZfTo0TJ69GhJT0+Xpk2byuzZs2XZsmVSv359EREJDw+Xdu3aGc/Vt29fGTlypHzzzTeSmpoq5cuXl+7duyvvJfLrX2CunA++UaVKFWWebN68WWrVqiUNGzYssE9R5pav1a9fXyzLknr16hX6yxbexfyBp5hDKIqmTZvKli1b5MKFC8qV3B07duS/XhB358/ly5eld+/eUrlyZXnnnXdsBa+79ZEzderUkc2bN0t2drZytfnw4cP5r/szv/oT4Oeff5bNmzdLr169pHz58i71ueeee6Rdu3b5/7Vo0aLAY3NycvL/SeOG+vXrS2hoaP4/f3Ts2FEqVqwoiYmJcvXqVadjvFlcXJwEBATIO++8IytXrpRu3bop9yFs1qyZ1K9fX5KTk53eWkg/H3wvNTVVdu3aJQkJCYX+FezO3CouvXv3loCAAHn55Zdt//JgWZZkZWWV0MhuH8wfeIo5BFc98cQTcv36deXuJ7m5ubJo0SKJjo6WiIiIAvu6O3+GDx8uR44ckbS0NGXJ6A3u1kfOdOnSRa5fvy6vvvqq0j537lxxOBzSuXNn4zlKkl9daU5NTZVr1665vDTDXUeOHJG2bdtKfHy8NG7cWAIDAyUtLU1OnTol/fr1E5Ffrwi//vrr8uSTT8pvf/tb6devn1StWlUyMzNl/fr10qJFC+WbHR4eLq1bt5Y5c+ZIdna29O3bV3nPMmXKyMKFC6Vz587SpEkTGTJkiNSsWVNOnDghW7ZskYoVK8p7773nk88Lka1bt8rUqVOlQ4cOEhYWJl9++aUsWrRIOnXqJM8++2xJD89t9evXl+nTp8v48eMlIyNDYmNjJTQ0VL7//ntJS0uToUOH5t8AH55j/sBTzCF4Ijo6Wvr06SPjx4+Xn376Se69915ZsmSJZGRkyFtvveW191m/fr0sXbpU4uLiZN++fbJv377810JCQiQ2Ntbt+siZ7t27S+vWrWXixImSkZEhDzzwgGzcuFHWrl0rCQkJ+Vez/ZVfFc3Lly/36LK/SUREhPTv318++ugjSUlJkcDAQGnYsKGsWLFCWew+YMAAqVGjhvzlL3+RpKQkyc3NlZo1a0pMTIwMGTLEdt6+ffvK5s2bJTQ0VLp06WJ7/fHHH5ft27fLtGnT5NVXX5WLFy9KtWrVJDo6WoYNG+aTz4pf1axZUwICAiQpKUmys7OlXr16Mn36dHn++edL7eNjx40bJ1FRUTJ37tz89WoRERHSoUMHl5c1wTXMH3iKOQRPLV26VCZNmiQpKSly9uxZuf/++2XdunXSqlUrr73HjavEq1evtj2lsk6dOhIbGysi7tdHujJlysi//vUveemllyQ1NVUWLVokdevWlaSkJBk9erTXPo+v+O1jtAEAAAB/4VdrmgEAAAB/RNEMAAAAGFA0AwAAAAYUzQAAAIABRTMAAABgQNEMAAAAGFA0AwAAAAYu31nd4XD4chzwA768ZTfz59bn61u+M4duffwMgieYP/CEK/OHK80AAACAAUUzAAAAYEDRDAAAABhQNAMAAAAGFM0AAACAAUUzAAAAYEDRDAAAABhQNAMAAAAGFM0AAACAAUUzAAAAYEDRDAAAABhQNAMAAAAGFM0AAACAAUUzAAAAYEDRDAAAABhQNAMAAAAGFM0AAACAAUUzAAAAYEDRDAAAABhQNAMAAAAGgSU9AAAAALimW7duSm7durWxT2RkpJK7du2q5DJl1GuoeXl5tnNMmzZNyW+99ZaSjx8/bhxHaceVZgAAAMCAohkAAAAwoGgGAAAADByWZVkuHehw+HosLgsKClLy2LFjlfzSSy/Z+gQGFr58W/98y5Ytsx0zceJEJWdmZhZ6ztLGxalQJP40f7yhWbNmSl6xYoWS69Wr5/Y5T548aWtbuXKlkidNmqTk7Oxst9/HV3w5f0RuvTlk0qlTJ1tbbGyskocOHapkZ9+Dzz//XMmJiYlK/vDDD4s4Qu/jZ5BvlStXTskhISFKXrx4sa1P9+7dlXzu3Dklt2jRwtbn0KFDRRugh27F+fPII4/Y2jZt2qTk8uXLK7koXwf98xXlHKtXr7a1/fOf/1RyWlqa2+ctLq58Zq40AwAAAAYUzQAAAIABRTMAAABgUCrXNI8YMULJr776arG8b3p6upL79u2r5H379tn6+HqdpzfdiuvBvKV///5K/sc//qFkfZ390qVLbefYv39/oe/RsWNHW1vbtm2V/Nprryl51KhRhZ6zOLGm2T1Vq1ZV8vjx45X87LPP2vroX2NX1iGajjHt9yhO/AwqOn298nPPPWc7Rr+fb/v27Y3nPXPmjJL1n30vvviiq0P0uVth/uhrmGfOnGk7JiYmRslFWY985MgRJR89elTJXbp0MZ5D5+xrpO+70dc0//GPf7T1ycnJcfu9vYE1zQAAAIAXUDQDAAAABhTNAAAAgAFFMwAAAGDg9xsBO3fubGtbvny5kitVqqTkH374wdbnxIkThb5PhQoVlNy4cWNXh5hPf8CFiMisWbOU/NVXX7l93uJyK2yi8AZ905+IyMKFC5Wcl5enZP2BOq+88ortHNeuXSv0fTt06GBr27Bhg5JPnTql5Bo1ahR6zuLERsDC6Rv/Pv30UyU3aNBAyc4+r/41zsrKUnJYWJitj2mTUEBAQAEjLn78DHKd/jtq7ty5Sm7Xrp2tj/5gEn1z+65du2x99M3Hhw8fdmeYxepWmD+pqalKjouLM/bRx+asBurVq5eS9e/9pUuXlPz000/bznHvvfcWOo7HH3/c1vbggw8W2uf999+3tfXo0aPQPr7CRkAAAADACyiaAQAAAAOKZgAAAMDAf+5qX4AxY8bY2vQ1zLorV67Y2vr166fkjIyMQs8ZHx9vO8ef/vQnJf/8889K7tOnj61Pz549lTxx4kQlp6Sk2PqcPn3a1obiM3v2bFubvoa5d+/eSt60aZPxvMHBwUqeN2+ekvV19Si99PXLIva1e/oaZn093YIFC2zn0NeT6muak5OTjWM5dOiQkxHD3w0aNEjJ06ZNU3KtWrWUvGfPHts5Jk2apOQPPvhAyfrDT0RErl696tY44Rl9fbIra6nLlFGvfzp7sM2///1vt8Yxf/58t44vyOuvv67kwYMHK7lr1662PvoeoalTp3plLN7AlWYAAADAgKIZAAAAMKBoBgAAAAz8fk3z4sWLbW3O7gV4s3vuucfWFhsbq+S//vWvSj5//ryS33zzTds5Vq9ereTs7Gwl33///bY++j2l9TWHv/vd72x9BgwYYGuD7+j3R65WrZrtGP1778oaZt3ly5eVvH37diU7ux+nfu9vZ2tWUfJM92AWsa9hzsnJUXJaWpqSR4wY4fY4li1b5nYf+J+oqChbm2kN8/r165X8+9//3naOihUrKnnz5s1KjomJMb7v9OnTnYwY3qLfY9mVewfre278if5zLDMzU8n6/BIRGTt2rJI3btyo5C+//NJLo3MfV5oBAAAAA4pmAAAAwICiGQAAADCgaAYAAAAM/H4j4MqVK21tL7zwgpIbN26sZGeL4vfu3evxWM6cOVPo67t377a16RvGIiMjlRweHu7xuOBdzjZeJCUlef199IdXOHuYBUqHpUuXKlnf9Cdin1f6xj/94RVF0bBhQ1ub/kAl/Rhnm5FRsvSNxyL2jX/6w7X69++vZGcb5vVNVw888IBxLM5+r8F39AfQOHvgTJMmTYprOF6n/54bNWqU7Ri9LtK/BmwEBAAAAPwYRTMAAABgQNEMAAAAGPj9muYrV67Y2gYPHqzkKVOmKHn+/Pm2Plu2bPHmsJwqV66crc20XnDu3Lm+Gg5KGWfrUaOjo5W8ZMmS4hoOCqGvDdUfkONwOGx9EhMTlayvXSyK5557Tsnjxo2zHaM/eEVfW92rVy9bH329NXxL/z3QqFEjY5/g4GAl6w8qadasma1PQEBAoef84osvbG36gyXgW/pD0y5evFhCI/GNrKwsJTtbn9yjRw8ld+nSRckzZ870/sBcxJVmAAAAwICiGQAAADCgaAYAAAAM/H5NszP6fSO7d+9eQiNRxcXF2dpMa5qvXr3qq+HAi8aOHavkPn36eHzOoUOHKnny5Mm2Y06dOqVk1jT7hwkTJijZdA9mEffX4elrkUXs94PW11I7u8e43ubKWFG8HnroISU7WxOvCwkJUfLDDz+s5EuXLtn6VKhQodBzPvHEE7a269evG8cC33E2F/S2b775RsmrVq3y6Zi8aevWrba2nj17KrlMGf+5vus/IwEAAAD8FEUzAAAAYEDRDAAAABiUyjXN/mrx4sXGY3Jzc5XsbN0Zipd+H9K9e/fajtHXq7/xxhtK/uqrr5RcuXJl4zmc3UdV99NPPxmPgW/pa89FzGtO//73v9vaateurWR9fWlsbKySJ06caDuHvh7ZlbWv+jGnT5829kHxevLJJ5X8zjvv2I7R1zDn5OQo+bXXXlNyaGio7RzO5iX8myv7FKZOnVpcw/G69evX29qSk5OVHBkZqeSoqChbnyNHjnh3YAXgSjMAAABgQNEMAAAAGFA0AwAAAAYUzQAAAIABGwE9ULNmTSW7sinn8OHDSt62bZtXxwTP6TdWFxFZvny5kp955hkl6997Z5s39I0K+ubBpk2b2vroD/KBfzA9MMTZQ2juuusuJZcvX96tcxbU5s7rIiKJiYnGY1C8MjIylPzoo496fM61a9d6fA6UDq7UHv7KlQ18d955Z6G5OHGlGQAAADCgaAYAAAAMKJoBAAAAA9Y0e2DcuHFKDggIMPY5evSor4YDLzl+/LitrW3btkpu1KhRoa9/9NFHtnOcOXNGyZs2bTKOZfXq1cZj4FsLFiywtSUkJCi5QYMGSq5Tp46tj+nBJPpDR4YPH24c24wZMwodh4h9Puvr83H70ueG/vAtlLw9e/bY2qKjo5XcpUsXJTt7OE5pdvLkyUJzceJKMwAAAGBA0QwAAAAYUDQDAAAABqxpdkNsbKyShw0bZuxz6dIlJc+ePdubQ0IxuXr1qpL37dtXaHbmtddeU3JUVJSSnd2T2dnaaJS8hx56SMm9evVS8tdff208h74u/rPPPlNyZmamrc/EiROVrK9hdnaf5q1btypZXzuN29fHH3+s5HPnzpXMQFAg/f9fEZGRI0cquU2bNkrW7wEvIpKTk+PdgXnJSy+9ZGvT93vo97gPCwuz9Tl27Jh3B1YArjQDAAAABhTNAAAAgAFFMwAAAGBA0QwAAAAYsBHQDfoDLFx5mMmHH36o5B07dnh1TPBPI0aMcKntZm+++aat7ZdffvHamOA9+qaaojwwxNlDC27m7AEpo0aNUrK+YcaZxMRE9waGUknfHHXPPfeU0EjgTc427uoPoalWrZqS9YediIisWrXKuwMrokceeUTJY8eOtR2jb2ieOnWqkk0/O32JK80AAACAAUUzAAAAYEDRDAAAABiwprkA999/v62tb9++bp9n48aN3hgO/FxoaKiS+/XrZztGX6elP8xkwYIF3h8YSq05c+bY2vR1q/qcevfdd219Dh8+7N2BwS/dfffdSm7cuLGxDw/b8n9btmyxtW3btk3J+sNN9HXDzs6TlZXlhdG5T98bFhwcbOyTnp7uq+G4jSvNAAAAgAFFMwAAAGBA0QwAAAAYOCx9UVxBB7pwP9BbyWeffWZra968eaF9fvjhB1tbRESE18bkay5OhSK51edPQkKCkp2tFdTXkHXr1k3JO3fu9Pq4ipMv54/IrT+HqlatquRTp07ZjtG/xsePH1dyp06dbH1K05pmfgYVnb6Gef/+/bZj9LbWrVsr+ezZs94fWDG6XeaPvofm3LlzSnb2ddDXQeu/f7Kzs70zOM0zzzyj5L/97W9KLleunK3PpUuXlNyqVSsl792710ujU7kyf7jSDAAAABhQNAMAAAAGFM0AAACAAUUzAAAAYMDDTf6nQYMGSo6KinL7HF27dvXWcFDKxMXFGY9ZtGiRkkv7xj94Rt/4p28edbYpRW9LTExUcmna9Ifil5GRoeTSvvHvdqVv2qtcubKS09LSbH1atGihZH3zYO/evZW8Z88e2zlycnKU/Msvvyh5ypQptj56XRQUFKTkixcv2vroD2vx1ca/ouBKMwAAAGBA0QwAAAAYUDQDAAAABrftmuYKFSoo+c9//rOS77rrLrfP+fXXX3s0JpQeffr0UXLLli2V/M0339j6zJ8/36djQunSrFkzJQ8cOFDJZcrYr2l8+umnSl6wYIH3B4ZbVlhYmJL134P6QyVQOuhrnNu1a2c7Zvjw4UqeM2eOkt99910lO9tT8d///lfJZ86cUfIDDzxg66Of5/Tp00rW11KLiOzevdvW5i+40gwAAAAYUDQDAAAABhTNAAAAgMFtu6a5Tp06Sh4wYIDb53j77beVfO3aNY/GBP9Vu3ZtJc+aNUvJ+rot/XURke+++877A0OptWTJEiXrcygvL8/WR78vM+CO5s2bKzkiIkLJ3Of71vXGG28oWa9XXNlzU6tWrUKzM1lZWUqeOXOmkrdt22Y8hz/hSjMAAABgQNEMAAAAGFA0AwAAAAYUzQAAAIDBbbsR0Bt++uknJTu7GThuDZMnT1ayvpH0rbfeUnJKSorPx4TSZdiwYUoODw9Xsr7xb+PGjbZzOGsDXJWZmank8+fPl9BIUNIWLlyo5IYNGyrZWT0TFRWl5B9++EHJzh6Ok5aWpuTStvFPx5VmAAAAwICiGQAAADCgaAYAAAAMbts1zfoNt5cvX67kgQMH2vocOHBAyfpNunHrqlKlSqGvb926Vck86Aa6gwcPKllfw6yvIXzyySd9PibcXvbu3avkkydPltBI4G/GjBlT0kMoFbjSDAAAABhQNAMAAAAGFM0AAACAgcNy8ebCDofD12NBCfPlfaaZP7c+X9+nnDl06+NnEDzB/IEnXJk/XGkGAAAADCiaAQAAAAOKZgAAAMCAohkAAAAwoGgGAAAADCiaAQAAAAOKZgAAAMCAohkAAAAwcPnhJgAAAMDtiivNAAAAgAFFMwAAAGBA0QwAAAAYUDQDAAAABhTNAAAAgAFFMwAAAGBA0QwAAAAYUDQDAAAABhTNAAAAgMH/AbSRe79uCn3VAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x900 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,9))\n",
    "row,colm = 1,5\n",
    "for i in range(1,row*colm+1):\n",
    "    random_index = torch.randint(1,len(train_data),size=[1]).item()\n",
    "    image,label = train_data[random_index]\n",
    "    fig.add_subplot(row,colm,i)\n",
    "    plt.title(class_name[label])\n",
    "    plt.axis(False)\n",
    "    plt.imshow(image.squeeze(),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Turn the MNIST train and test datasets into dataloaders using torch.utils.data.DataLoader, set the batch_size=32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader =  DataLoader(dataset=train_data,batch_size=32,shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data,batch_size=32)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Recreate model_2 used in this notebook (the same model from the <a href='https://poloclub.github.io/cnn-explainer/'>CNN Explainer website</a>, also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self,input_shape,output_shape,hidden_units):\n",
    "        super().__init__()\n",
    "        self.block_1= nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,out_channels=hidden_units,kernel_size=3,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7,out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.linear_layer(x)\n",
    "\n",
    "\n",
    "model_0 = MNISTModel(input_shape=1,output_shape=len(class_name),hidden_units=10)\n",
    "next(model_0.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train the model you built in exercise 8. on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Epoch: 0----\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x160 and 490x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model_0\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch,(X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m----> 8\u001b[0m     y_prod \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(y_prod\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_pred)\n",
      "Cell \u001b[0;32mIn[103], line 26\u001b[0m, in \u001b[0;36mMNISTModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_1(x)\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_2(x)\n\u001b[0;32m---> 26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/Projects/Python/Torch/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/Projects/Python/Torch/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Development/Projects/Python/Torch/env/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Development/Projects/Python/Torch/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/Projects/Python/Torch/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Development/Projects/Python/Torch/env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x160 and 490x10)"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"----Epoch: {epoch}----\")\n",
    "    model_0.train()\n",
    "    for batch,(X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "        y_prod = model_0.forward(X)\n",
    "\n",
    "        y_pred = torch.softmax(y_prod.argmax(dim=1))\n",
    "        print(y_pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
